{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import geocoder\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn import grid_search\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~Assistant Function~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize number of people to groups\n",
    "def peoples_to_catg(i):\n",
    "    if (i==1.0)|(i==9.0):\n",
    "        return 1\n",
    "    if (2.0<=i<=4.0)|(i==8.0):\n",
    "        return 2\n",
    "    if 5.0<=i<=7.0:\n",
    "        return 3\n",
    "\n",
    "# categorize number of children to groups\n",
    "def children_to_catg(i):\n",
    "    if 0<=i <=3:\n",
    "        return 1\n",
    "    if 4<=i<=8:\n",
    "        return 2\n",
    "    if 9<=i:\n",
    "        return 3\n",
    "\n",
    "# convert ordinal categorical variables to order number\n",
    "def ordinal_to_numeric(x):\n",
    "    if x =='low':\n",
    "        return 1\n",
    "    if x=='medium':\n",
    "        return 2\n",
    "    if x=='high':\n",
    "        return 3\n",
    "\n",
    "# convert categorical variables to binary ones using one-hot\n",
    "def onehot(df,columns=[]):\n",
    "    for i in columns:\n",
    "        dummies=[x for x in list(df[i].unique()) if str(x) != 'nan']\n",
    "        for dummy in dummies:\n",
    "            df[i+'.'+str(dummy)]=(df[i]==dummy).astype(int)\n",
    "    df=df.drop(columns,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "All = pd.concat((train, test))\n",
    "print('Original Feature set:', All.columns)\n",
    "print('length of train set:', len(train))\n",
    "print('length of test set:', len(test))\n",
    "print('length of all data:', len(All))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of all data: **9990**, Training set: **7578**, Hold-out set (with out target label):**2412**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Remove Abnormal Value in Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Target varibale \"cancel\" contains:', list(train.cancel.unique()))\n",
    "print('length of abnormal value in \"cancel\": ', len(train[train.cancel==-1]))\n",
    "train=train[train.cancel!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target varibale \"cancel\" contains: [0, 1, -1] \n",
    "<br>length of abnormal value in \"cancel\":  25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Convert Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('******************convert outlier****************************')\n",
    "# 'feature A should be limited to 100, so all observations with value of A >100 are capped as 100\n",
    "train.loc[train['ni.age']>=100,'ni.age'] = 100\n",
    "test.loc[test['ni.age']>=100,'ni.age'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Remove Adnormal Value in Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('******************adnormal value in target variable*************')\n",
    "train=train[train.cancel!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('******************review missing values**********************')\n",
    "print('train: \\n',train.isnull().sum())\n",
    "print('\\n')\n",
    "print('test: \\n',test.isnull().sum())\n",
    "print('*************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import missing values in categorical variables with mode based on all data\n",
    "train['B'] = train['B'].fillna(value=All['B'].mode())\n",
    "test['B'] = test['B'].fillna(value=All['B'].mode())\n",
    "\n",
    "# import missing values in numeric variables with mean based on all data\n",
    "train['C']=train['C'].fillna(value=All['C'].mean())\n",
    "test['C']=test['C'].fillna(value=All['C'].mean())\n",
    "\n",
    "# remove missing value casue feature D only have one missing value in training dataset\n",
    "train['D']=train[train['D'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction and Enginnering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('******************Geocoding************************************')\n",
    "for i in train.index:\n",
    "    print(i)\n",
    "    try:\n",
    "        g=geocoder.arcgis(str(int(train.loc[i,'zip.code'])))\n",
    "        train.loc[i,'zip.city']=g.address.split(', ')[1] \n",
    "        train.loc[i,'zip.state']=g.address.split(', ')[2]\n",
    "        train.loc[i,'zip.lat']=g.lat\n",
    "        train.loc[i,'zip.lon']=g.lng\n",
    "    except:\n",
    "        train.loc[i,'zip.city']='Other' \n",
    "        train.loc[i,'zip.state']='Other'\n",
    "        train.loc[i,'zip.lat']=0.0\n",
    "        train.loc[i,'zip.lon']=0.0\n",
    "    time.sleep(0.3)\n",
    "\n",
    "for i in test.index:\n",
    "    print(i)\n",
    "    try:\n",
    "        g=geocoder.arcgis(str(int(test.loc[i,'zip.code'])))\n",
    "        test.loc[i,'zip.city']=g.address.split(', ')[1] \n",
    "        test.loc[i,'zip.state']=g.address.split(', ')[2]\n",
    "        test.loc[i,'zip.lat']=g.lat\n",
    "        test.loc[i,'zip.lon']=g.lng\n",
    "    except:\n",
    "        test.loc[i,'zip.city']='Other' \n",
    "        test.loc[i,'zip.state']='Other'\n",
    "        test.loc[i,'zip.lat']=0.0\n",
    "        test.loc[i,'zip.lon']=0.0\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train['zip.city'].unique()))\n",
    "print(len(train['zip.state'].unique()))\n",
    "print(len(test['zip.city'].unique()))\n",
    "print(len(test['zip.state'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 states, 125 cities in both of training and holdout dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) rank city and zipcode based on average house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('********rank city and zipcode based on market info*******************')\n",
    "Train_rank=pd.read_csv('Train_price_rank.csv')\n",
    "Train_rank=Train_rank.drop(['zip.state','zip.city'],axis=1)\n",
    "Test_rank=pd.read_csv('Test_price_rank.csv')\n",
    "Test_rank=Test_rank.drop(['zip.state','zip.city'],axis=1)\n",
    "train=train.merge(Train_rank, how='left', on='zip.code')\n",
    "test=test.merge(Test_rank, how='left', on='zip.code')\n",
    "\n",
    "values = {'state_median_rank':0,'state_per_sqft_rank':0,'city_median_rank':0,'city_per_sqft_rank':0,'code_median_rank':0,'code_per_sqft_rank':0}\n",
    "train=train.fillna(value=values)\n",
    "test=test.fillna(value=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Feature Transforamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stanardizaion\n",
    "train['D'] = (train['D']-train['D'].mean())/train['B'].std()\n",
    "test['D'] = (test['D']-train['D'].mean())/test['B'].std()\n",
    "\n",
    "# cluster (numberic - categorical)\n",
    "train['B_cat'] = train['B'].apply(peoples_to_catg)\n",
    "test['B_cat'] = test['B'].apply(peoples_to_catg)\n",
    "\n",
    "# round value to int (some features like year, number of people, should not have decimal number)\n",
    "train['E_round'] = round(train['E'],0)\n",
    "test['E_round'] = round(test['E'],0)\n",
    "\n",
    "# log transformation\n",
    "train['I_log']=np.log10(train['I'])\n",
    "test['I_log']=np.log10(test['I'])\n",
    "\n",
    "# perform onehot on categorical variables\n",
    "train=onehot(train,columns=['F','G','H'])\n",
    "test=onehot(test,columns=['F','G','H'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features are generated based on business or mathmatic relationship between original features.\n",
    "# Only code examples are shown as follows\n",
    "train['A+B'] = train['A'] + train['B']\n",
    "train['A/B'] = train['A']/train['B']\n",
    "# create interaction features\n",
    "train['A*B'] = train['A'].values*train['B'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   1. Removed features based on improvement of model performance and feature importance.<br>\n",
    "   2. Evaluate the selected features using monte carlo cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = train.columns\n",
    "removed_features = ['feature list' ]\n",
    "selected_features = [f for f in orginal_features if f not in removed_features]\n",
    "X_train = train[selected_features]\n",
    "y_train = train['cancel'].values\n",
    "X_test = test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Fit in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best parameter C and AUC Score\n",
    "LRCV=LogisticRegressionCV(Cs=[10**i for i in range(-5,4)],cv=10,n_jobs=4,solver='liblinear',scoring='roc_auc',penalty='l1',random_state=7)\n",
    "LRCV.fit(X_train,y_train)\n",
    "print('score for 10 Cs:',LRCV.scores_[1].mean(axis=0))\n",
    "print('Best Score:',LRCV.scores_[1].mean(axis=0).max())\n",
    "lst=list(LRCV.scores_[1].mean(axis=0))\n",
    "index=lst.index(LRCV.scores_[1].mean(axis=0).max())\n",
    "print('All chosen Cs:', LRCV.Cs_)\n",
    "print('C for Best Score:', LRCV.Cs_[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Fit in XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best parameters and AUC Score\n",
    "param_grid = {   \n",
    "             'n_estimators': [300],\n",
    "             'learning_rate': [0.02],\n",
    "             'max_depth':[1],\n",
    "             'min_child_weight':[1],\n",
    "             'gamma':[0.0],\n",
    "             'subsample':[0.6],\n",
    "             'colsample_bytree':[0.2],\n",
    "             'reg_alpha':[0.13]\n",
    "             'reg_lambda':[0.005]\n",
    "   } # create parameter space to search\n",
    "\n",
    "start_time = time.time()\n",
    "xgb = XGBClassifier(\n",
    "        seed=7,\n",
    "        verbose=100,\n",
    "        objective='binary:logistic',\n",
    "        booster='gbtree',\n",
    "        n_estimators = 1500,\n",
    "        learning_rate = 0.02,\n",
    "        max_depth = 5,\n",
    "        min_child_weight = 2,\n",
    "        gamma = 0.0,\n",
    "        subsample = 0.6,\n",
    "        colsample_bytree = 0.2,\n",
    "        reg_alpha = 0.13\n",
    "        reg_lambda = 0.005        \n",
    "        \n",
    "        )\n",
    "\n",
    "model = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=10, verbose=20,n_jobs=8, scoring='roc_auc')\n",
    "model.fit(X_train,y_train)\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "print('Param grid:')\n",
    "print(param_grid)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check feature importance\n",
    "xgb = XGBClassifier(\n",
    "        seed=7,\n",
    "        verbose=100,\n",
    "        objective='binary:logistic',\n",
    "        booster='gbtree',\n",
    "        n_estimators = 1500,\n",
    "        learning_rate = 0.02,\n",
    "        max_depth = 5,\n",
    "        min_child_weight = 2,\n",
    "        gamma = 0.0,\n",
    "        subsample = 0.6,\n",
    "        colsample_bytree = 0.2,\n",
    "        reg_alpha = 0.13\n",
    "        reg_lambda = 0.005        \n",
    "        )\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "f_impor = pd.DataFrame(data={'features':selected_featureas,'importance':xgb.feature_importances_})\n",
    "f_impor = f_impor.sort_values(by='importance')\n",
    "\n",
    "f_impor.plot.bar(x='features',y='importance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Monte Carlo Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression(C=0.5,penalty='l1',random_state=7,solver='liblinear', n_jobs=4)\n",
    "col_name = X_train.colums\n",
    "\n",
    "\n",
    "\n",
    "mccvdf = pd.DataFrame()\n",
    "\n",
    "for i in col_name:\n",
    "    mccvdf.loc[:,i] = []\n",
    "\n",
    "\n",
    "def MCCV(train,label,seed):\n",
    "    \n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(train, label, test_size=0.40, random_state=seed)\n",
    "    LR.fit(data_train, labels_train)\n",
    "    coefList = LR.coef_.tolist()[0]\n",
    "    \n",
    "    return coefList\n",
    "    \n",
    "for i in range(0,2000):\n",
    "    coefficient = MCCV(X_train, y_train, seed=i)\n",
    "    record = pd.Series(coefficient, index=col_name)\n",
    "    mccvdf = mccvdf.append(record, ignore_index=True)\n",
    "\n",
    "for i in range(mccvdf.shape[1]):\n",
    "    plt.hist(mccvdf.iloc[:,i].values,bins=50)\n",
    "    plt.title(col_name[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Tuning and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = train.columns\n",
    "removed_features = [ 'feature list' ]\n",
    "selected_features = [f for f in orginal_features if f not in removed_features]\n",
    "X_train = train[selected_features]\n",
    "y_train = train['cancel'].values\n",
    "X_test = test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Logistic Regression Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRCV=LogisticRegressionCV(Cs=[10**i for i in range(-5,4)],cv=10,n_jobs=4,solver='liblinear',scoring='roc_auc',penalty='l1',random_state=7)\n",
    "LRCV.fit(X_train,y_train)\n",
    "print('score for 10 Cs:',LRCV.scores_[1].mean(axis=0))\n",
    "print('Best Score:',LRCV.scores_[1].mean(axis=0).max())\n",
    "lst=list(LRCV.scores_[1].mean(axis=0))\n",
    "index=lst.index(LRCV.scores_[1].mean(axis=0).max())\n",
    "print('All chosen Cs:', LRCV.Cs_)\n",
    "print('C for Best Score:', LRCV.Cs_[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) GBM tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'max_depth': [],\n",
    "        'min_samples_split':[],\n",
    "        'min_samples_leaf':[],\n",
    "        'max_features':[],\n",
    "        'subsample':[],\n",
    "        'n_estimators':[],\n",
    "        'learning_rate':[]\n",
    "        \n",
    "    }\n",
    "\n",
    "start_time = time.time()\n",
    "clf = GradientBoostingClassifier(\n",
    "    min_samples_split=75, #1% of 7552\n",
    "    min_samples_leaf=7, # 10% of min_sample_split\n",
    "    max_depth=5, # choose a number between 5 and 8\n",
    "    max_features='sqrt', # tumb of rule\n",
    "    subsample=0.8,\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.005,\n",
    "    random_state=7)\n",
    "\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10, verbose=20, scoring='roc_auc')\n",
    "model.fit(X, y)\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "print('Param grid:')\n",
    "print(param_grid)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'C': [], \n",
    "    'gamma': []\n",
    "}\n",
    "model = GridSearchCV(SVC(kernel='rbf',probability=True), param_grid=params, verbose=20, n_jobs=8, cv=10, scoring='roc_auc')\n",
    "model.fit(X,y)\n",
    "print('Param grid:')\n",
    "print(params)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {   \n",
    "             'n_estimators': [],\n",
    "             'learning_rate': [],\n",
    "             'max_depth':[],\n",
    "             'min_child_weight':[],\n",
    "             'gamma':[],\n",
    "             'subsample':[],\n",
    "             'colsample_bytree':[],\n",
    "             'reg_alpha':[]\n",
    "             'reg_lambda':[]\n",
    "   } # create parameter space to search\n",
    "\n",
    "start_time = time.time()\n",
    "xgb = XGBClassifier(\n",
    "        seed=7,\n",
    "        verbose=100,\n",
    "        objective='binary:logistic',\n",
    "        booster='gbtree',\n",
    "        n_estimators = 1500,\n",
    "        learning_rate = 0.02,\n",
    "        max_depth = 5,\n",
    "        min_child_weight = 2,\n",
    "        gamma = 0.0,\n",
    "        subsample = 0.6,\n",
    "        colsample_bytree = 0.2,\n",
    "        reg_alpha = 0.13\n",
    "        reg_lambda = 0.005        \n",
    "        \n",
    "        )\n",
    "\n",
    "model = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=10, verbose=20,n_jobs=8, scoring='roc_auc')\n",
    "model.fit(X_train,y_train)\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "print('Param grid:')\n",
    "print(param_grid)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide Model Ensemble Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models # n base models at the first level\n",
    "\n",
    "\n",
    "        \n",
    "    def fit_predict(self, X, y, T, seed): # y_pred = ensemble.fit_predict(X=X_train, y=y_train, T=X_test)\n",
    "        X = np.array(X) # X_train\n",
    "        y = np.array(y) # y_train\n",
    "        T = np.array(T) # X_test\n",
    "\n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True,random_state=seed)) # generate index for kfolds\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models))) # create N_train_rows* n_models array\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models))) # create N_test_rows* n_models array\n",
    "\n",
    "        for i, clf in enumerate(self.base_models): # fit the i th base model\n",
    "\n",
    "            print('Fitting For Base Model #{0} / {1} ---'.format(i+1, len(self.base_models)))\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], len(folds))) # create N_test_rows* n_folds array\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds): # use the i th base model to fit the j th fold\n",
    "\n",
    "                print('--- Fitting For Fold #{0} / {1} ---'.format(j+1, self.n_folds))\n",
    "\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "\n",
    "                clf.fit(X_train, y_train) \n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1] #get prediction from the j th fold\n",
    "                S_train[test_idx, i] = y_pred # put into S_train\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1] # put into S_test\n",
    "\n",
    "                print('Elapsed: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "\n",
    "            S_test[:, i] = S_test_i.mean(1) \n",
    "\n",
    "            print('Elapsed: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "\n",
    "        print('--- Base Models Trained: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "\n",
    "        param_grid = {\n",
    "             'n_estimators': [1000],\n",
    "             'learning_rate': [0.002],\n",
    "             'max_depth':[2],\n",
    "             'min_child_weight':[19],\n",
    "             'gamma':[0],\n",
    "             'subsample':[0.5],\n",
    "             'colsample_bytree':[0.5],\n",
    "             'reg_alpha':[0.003]\n",
    "             #'reg_lambda':[0.005]\n",
    "        }\n",
    "        grid = grid_search.GridSearchCV(estimator=self.stacker, param_grid=param_grid, cv=10, verbose=200, scoring='roc_auc')\n",
    "        grid.fit(S_train, y)\n",
    "\n",
    "        #message = 'to determine local CV score of #28'\n",
    "\n",
    "        try:\n",
    "            print('Param grid:')\n",
    "            print(param_grid)\n",
    "            print('Best Params:')\n",
    "            print(grid.best_params_)\n",
    "            print('Best CV Score:')\n",
    "            print(-grid.best_score_)\n",
    "            print('Best estimator:')\n",
    "            print(grid.best_estimator_)\n",
    "            print(message)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('--- Stacker Trained: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "\n",
    "        y_pred = grid.predict_proba(S_test)[:,1]\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "print('--- Features Set: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "print('Number of Features: ', len(X_train.columns.tolist()))\n",
    "\n",
    "# Please input the tuned parameters for eahc model\n",
    "\n",
    "base_models = [\n",
    "        GradientBoostingClassifier(\n",
    "            n_estimators=,\n",
    "            learning_rate=,\n",
    "            random_state=, verbose=,\n",
    "            min_samples_split=, \n",
    "            min_samples_leaf=, \n",
    "            max_depth=, \n",
    "            max_features=,\n",
    "            subsample=\n",
    "        ),\n",
    "        XGBClassifier(\n",
    "            seed=,verbose=,\n",
    "            learning_rate=,\n",
    "            n_estimators=, \n",
    "            max_depth=,\n",
    "            min_child_weight = ,\n",
    "            gamma = ,\n",
    "            subsample=,\n",
    "            colsample_bytree=,\n",
    "            reg_alpha =  \n",
    "        ),\n",
    "        LogisticRegression(\n",
    "            C=,verbose=,\n",
    "            penalty=,\n",
    "            random_state=,solver=\n",
    "        ),\n",
    "        SVC(\n",
    "            probability=,\n",
    "            C=,\n",
    "            gamma=,\n",
    "            random_state=)\n",
    "    ]\n",
    "\n",
    "ensemble = Ensemble(\n",
    "        n_folds=,\n",
    "        stacker=XGBClassifier(\n",
    "            random_state=, verbose=\n",
    "        ),\n",
    "        base_models=base_models\n",
    "    )\n",
    "\n",
    "Random_avg = pd.DataFrame()\n",
    "for i in range(20): \n",
    "    y_pred = ensemble.fit_predict(X=X_train, y=y_train, T=X_test, seed=i)\n",
    "    Random_avg['y_predict'+str(i)]=y_pred\n",
    "print('--- Submission Generated: %s minutes ---' % round(((time.time() - start_time) / 60), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
